/**
 * Script import d·ªØ li·ªáu t·ª´ backup v√†o Docker MongoDB
 * Ch·∫°y trong Docker: docker exec -it nha-cho-backend node scripts/import-backup.js
 */

const { MongoClient } = require("mongodb");
const fs = require("fs");
const path = require("path");

const MONGO_URI =
  process.env.MONGODB_URI || 
  process.env.MONGO_URI || 
  "mongodb://mongodb:27017/nha-cho-sinh-vien";
const BACKUP_DIR = path.join(__dirname, "..", "..", "mongo-backup");

async function importData() {
  console.log("üì¶ B·∫Øt ƒë·∫ßu import d·ªØ li·ªáu v√†o MongoDB...\n");
  console.log("üìç MongoDB URI:", MONGO_URI.replace(/\/\/[^:]+:[^@]+@/, '//***:***@'));

  const client = new MongoClient(MONGO_URI);

  try {
    await client.connect();
    console.log("‚úì K·∫øt n·ªëi MongoDB th√†nh c√¥ng");

    const db = client.db();

    // ƒê·ªçc t·∫•t c·∫£ file JSON trong backup
    const files = fs.readdirSync(BACKUP_DIR).filter((f) => f.endsWith(".json"));
    console.log(`üì¶ T√¨m th·∫•y ${files.length} backup files\n`);

    for (const file of files) {
      const collName = file.replace(".json", "");
      const filePath = path.join(BACKUP_DIR, file);
      const data = JSON.parse(fs.readFileSync(filePath, "utf8"));

      if (data.length > 0) {
        // X√≥a collection c≈©
        await db.collection(collName).deleteMany({});

        // Import data m·ªõi
        await db.collection(collName).insertMany(data);
        console.log(`‚úì Imported ${collName}: ${data.length} documents`);
      }
    }

    console.log("\n‚úÖ Import ho√†n t·∫•t!");
  } catch (error) {
    console.error("‚ùå L·ªói:", error.message);
  } finally {
    await client.close();
  }
}

importData();
